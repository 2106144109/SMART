#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os,sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
import argparse
import torch

from smart.utils.config import load_config_act
from smart.utils.log import Logging
from smart.model import SMART
from smart.datasets.scalable_dataset import MultiDataset
from smart.datasets.maritime_dataset import MaritimeDataset
from smart.transforms import WaymoTargetBuilder, MaritimeTargetBuilder

# å¤ç”¨ç°æœ‰çš„ç»˜å›¾/é‡‡æ ·/æŒ‡æ ‡å‡½æ•°ï¼Œé¿å…é‡å¤å®ç°
import visualize_predictions_folium as vpf


def _parse_indices(indices_str: str, ds_len: int):
    """
    è§£æé€—å·åˆ†éš”çš„ç´¢å¼•å­—ç¬¦ä¸²ï¼Œè¿‡æ»¤éæ³•/è¶Šç•Œï¼Œå¹¶å»é‡ä¿åº
    """
    if not indices_str:
        return []
    raw = [s.strip() for s in indices_str.split(',') if s.strip()]
    parsed = []
    seen = set()
    for s in raw:
        if not s.isdigit():
            print(f"âŒ éæ³•ç´¢å¼•: {s}ï¼ˆå·²è·³è¿‡ï¼‰"); continue
        idx = int(s)
        if not (0 <= idx < ds_len):
            print(f"âŒ ç´¢å¼•è¶Šç•Œ: {idx}ï¼ˆ0 <= idx < {ds_len}ï¼Œå·²è·³è¿‡ï¼‰"); continue
        if idx not in seen:
            seen.add(idx)
            parsed.append(idx)
    return parsed


def build_dataset(config, split: str):
    data_cfg = config.Dataset
    dataset_classes = {"scalable": MultiDataset, "maritime": MaritimeDataset}
    transform_classes = {"scalable": WaymoTargetBuilder, "maritime": MaritimeTargetBuilder}
    ds_name = data_cfg.dataset
    dataset_class = dataset_classes[ds_name]
    transform_class = transform_classes[ds_name]

    if split == 'test':
        raw_dir = data_cfg.test_raw_dir
        processed_dir = data_cfg.test_processed_dir
    else:
        raw_dir = data_cfg.val_raw_dir
        processed_dir = data_cfg.val_processed_dir

    ds = dataset_class(
        root=data_cfg.root,
        split=split,
        raw_dir=raw_dir,
        processed_dir=processed_dir,
        transform=transform_class(config.Model.num_historical_steps,
                                  config.Model.decoder.num_future_steps)
    )
    return ds


def main():
    parser = argparse.ArgumentParser(description="å¯è§†åŒ–è‹¥å¹²æŒ‡å®š/æŠ½æ ·åœºæ™¯ï¼šå†å²+GTæœªæ¥+é¢„æµ‹ï¼ˆå«æŒ‡æ ‡ï¼‰")
    parser.add_argument('--config', type=str, default='configs/train/train_maritime.yaml')
    parser.add_argument('--pretrain_ckpt', type=str, required=True)
    parser.add_argument('--split', type=str, default='test', choices=['val', 'test'])

    # ç²¾ç¡®ç‚¹åä¼˜å…ˆç”Ÿæ•ˆï¼›å¦åˆ™æŒ‰æŠ½æ ·ç­–ç•¥
    parser.add_argument('--indices', type=str, default='', help='é€—å·åˆ†éš”ç´¢å¼•ï¼Œå¦‚ "12,345,678"')
    parser.add_argument('--num_scenes', type=int, default=5)
    parser.add_argument('--sample_mode', type=str, default=os.getenv('FOLIUM_SAMPLE_MODE', 'bucket'),
                        choices=['bucket', 'uniform', 'random'])
    parser.add_argument('--bucket_pick', type=str, default=os.getenv('FOLIUM_BUCKET_PICK', 'median'),
                        choices=['median', 'random', 'first', 'last'])
    parser.add_argument('--norm_stats', type=str, default=os.getenv('FOLIUM_NORM_STATS', ''))
    parser.add_argument('--output_dir', type=str, default='folium_pred_maps_selected')
    parser.add_argument('--no_save_map', action='store_true')
    args = parser.parse_args()

    print("="*80)
    print("ğŸ—ºï¸  é€‰æ‹©è‹¥å¹²åœºæ™¯å¯¹æ¯”ï¼šå†å² + æœªæ¥GT + é¢„æµ‹ï¼ˆå«æŒ‡æ ‡ï¼‰")
    print("="*80)
    print(f"é…ç½®: {args.config}")
    print(f"æƒé‡: {args.pretrain_ckpt}")
    print(f"æ•°æ®: {args.split}")
    print(f"è¾“å‡º: {args.output_dir}")
    print("="*80)

    # åŠ è½½é…ç½®/æ•°æ®
    config = load_config_act(args.config)
    ds = build_dataset(config, args.split)
    print(f"ğŸ“‚ æ•°æ®é‡: {len(ds)}")

    # å‡†å¤‡æ¨¡å‹
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logger = Logging().log(level='INFO')
    model = SMART(config.Model).to(device).eval()
    model.load_params_from_file(filename=args.pretrain_ckpt, logger=logger)

    # å½’ä¸€åŒ–ç»Ÿè®¡ï¼ˆå¯é€‰ï¼‰
    norm_stats = vpf._load_norm_stats(args.norm_stats)

    # ç¡®å®šåœºæ™¯ç´¢å¼•
    indices = _parse_indices(args.indices, len(ds))
    if not indices:
        if args.sample_mode == 'bucket':
            indices = vpf._pick_indices_bucket(ds, num_scenes=args.num_scenes, pick_mode=args.bucket_pick)
        elif args.sample_mode == 'uniform':
            indices = vpf._pick_indices_uniform(ds, num_scenes=args.num_scenes)
        else:
            seed_env = os.getenv('FOLIUM_SAMPLE_SEED')
            seed = int(seed_env) if (seed_env is not None and seed_env.strip() != '') else 0
            indices = vpf._pick_indices_random(ds, num_scenes=args.num_scenes, seed=seed)
    if not indices:
        print("âŒ æ— å¯è§†åŒ–æ ·æœ¬ã€‚"); return

    os.makedirs(args.output_dir, exist_ok=True)

    # é»˜è®¤ä¸­å¿ƒï¼ˆå¤‡ç”¨ï¼‰ï¼Œæœ€ç»ˆä¼šåœ¨ç»˜åˆ¶å‡½æ•°é‡ŒæŒ‰ scene_info/ç¯å¢ƒå˜é‡ä½¿ç”¨å‚è€ƒé”šç‚¹
    center_lat, center_lon = 30.0, 120.0

    print(f"\nğŸ—ºï¸  å¼€å§‹å¯è§†åŒ–(å…± {len(indices)} ä¸ªåœºæ™¯) ...")
    for out_idx, ds_idx in enumerate(indices):
        sample = ds[ds_idx].to(device)
        with torch.no_grad():
            pred = model.inference(sample)

        save_path = os.path.join(args.output_dir, f'scene_{out_idx:03d}.html')
        vpf._draw_scene_prediction_map(
            data=sample,
            pred=pred,
            output_path=save_path,
            scene_id=ds_idx,             # æŠ¥å‘ŠåŸå§‹æ•°æ®é›†ç´¢å¼•ï¼Œä¾¿äºå¤ç°
            center_lat=center_lat,
            center_lon=center_lon,
            norm_stats=norm_stats,
            save_map=not args.no_save_map
        )

    if not args.no_save_map:
        vpf._create_index_page(args.output_dir, len(indices))
    print("\nâœ… å…¨éƒ¨å®Œæˆï¼")


if __name__ == '__main__':
    main()