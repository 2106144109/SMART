#!/usr/bin/env python3
"""
ä¸º30ç§’é—´éš”æ•°æ®ç”ŸæˆMaritimeè½¨è¿¹è¯æ±‡è¡¨
"""

import os
import sys
sys.path.insert(0, '/home/mahexing/SMART-main')

from maritime_traj_clustering import create_maritime_vocabulary

if __name__ == '__main__':
    # ========== é…ç½®å‚æ•° ==========
    # è¯æ±‡è¡¨å¤§å°ï¼ˆtokenæ•°é‡ï¼‰
    NUM_CLUSTERS = 512  # â† ä¿®æ”¹è¿™é‡Œï¼æ¨èå€¼: 256/512/1024/2048
    
    # å®¹å·®è®¾ç½®ï¼ˆè°ƒæ•´èšç±»ç²¾ç»†åº¦ï¼‰
    # æ¨èå€¼ï¼š0.15(é»˜è®¤) / 0.12(+20%å¤šæ ·æ€§) / 0.10(+40%å¤šæ ·æ€§)
    TOLERANCE = 0.10  # â† ä¿®æ”¹è¿™é‡Œæ¥è°ƒæ•´å¤šæ ·æ€§
    # ================================
    
    # 30ç§’é—´éš”æ•°æ®çš„é…ç½®å‚æ•°
    config = {
        'data_dirs': [
            '/home/mahexing/SMART-main/data/maritime_windows_30s/train',
        ],
        'num_clusters': NUM_CLUSTERS,  # è¯æ±‡è¡¨å¤§å°
        'shift': 1,                    # æ—¶é—´æ­¥æ•°ï¼ˆ2ä¸ªç‚¹ï¼Œ30ç§’ï¼‰
        'max_samples': 50000,          # æœ€å¤§ä½¿ç”¨æ ·æœ¬æ•°ï¼ˆä¿æŒä¸å˜ï¼‰
        'ship_width': 10.0,            # èˆ¹èˆ¶å®½åº¦ï¼ˆä¿æŒä¸å˜ï¼‰
        'ship_length': 50.0,           # èˆ¹èˆ¶é•¿åº¦ï¼ˆä¿æŒä¸å˜ï¼‰
        'tolerance': TOLERANCE,        # èšç±»å®¹å·®
        'output_path': f'data/maritime_motion_vocab_30s_{NUM_CLUSTERS}tokens_shift{1}_tol{TOLERANCE:.2f}.pt'
    }
    
    print("\n" + "=" * 80)
    print("ğŸš¢ Maritimeè½¨è¿¹èšç±»è„šæœ¬ (30ç§’é—´éš”)")
    print("=" * 80)
    print("\nâš™ï¸ é…ç½®å‚æ•°:")
    print(f"  æ•°æ®æº: {config['data_dirs'][0]}")
    print(f"  â­ è¯æ±‡è¡¨å¤§å°: {NUM_CLUSTERS} tokens")
    print(f"  â­ å®¹å·®: {TOLERANCE}")
    print(f"  â­ æ—¶é—´æ­¥æ•° shift: {config['shift']} (2ä¸ªç‚¹, 30ç§’è½¨è¿¹)")
    print(f"  æœ€å¤§æ ·æœ¬æ•°: {config['max_samples']} (ä¿æŒä¸å˜)")
    print(f"  è¾“å‡ºè·¯å¾„: {config['output_path']}")
    
    # è¯æ±‡è¡¨å¤§å°è¯´æ˜
    vocab_hints = {
        256: "å°è¯æ±‡è¡¨ - é€‚åˆç®€å•åœºæ™¯/å¿«é€Ÿè®­ç»ƒ",
        512: "ä¸­ç­‰è¯æ±‡è¡¨ - å¹³è¡¡æ•ˆç‡å’Œè¡¨è¾¾åŠ›",
        1024: "è¾ƒå¤§è¯æ±‡è¡¨ - é€‚åˆä¸­ç­‰å¤æ‚åº¦",
        2048: "å¤§è¯æ±‡è¡¨ - æ ‡å‡†é…ç½®ï¼Œé«˜è¡¨è¾¾åŠ›",
        4096: "è¶…å¤§è¯æ±‡è¡¨ - æé«˜è¡¨è¾¾åŠ›"
    }
    vocab_hint = vocab_hints.get(NUM_CLUSTERS, f"{NUM_CLUSTERS} tokens (è‡ªå®šä¹‰)")
    print(f"\n  é…ç½®è¯´æ˜: {vocab_hint}")
    
    # å®¹å·®è¯´æ˜
    diversity_hint = {
        0.15: "æ ‡å‡†å¤šæ ·æ€§",
        0.12: "+20%å¤šæ ·æ€§",
        0.10: "+40%å¤šæ ·æ€§",
        0.08: "+60%å¤šæ ·æ€§",
    }
    hint = diversity_hint.get(TOLERANCE, "è‡ªå®šä¹‰è®¾ç½®")
    print(f"  å®¹å·®æ•ˆæœ: {hint}")
    
    # æ£€æŸ¥æ•°æ®ç›®å½•
    if not os.path.exists(config['data_dirs'][0]):
        print(f"\nâŒ é”™è¯¯ï¼šæ•°æ®ç›®å½•ä¸å­˜åœ¨ï¼")
        print(f"   è¯·å…ˆè¿è¡Œ: bash regenerate_30s_data.sh")
        sys.exit(1)
    
    # åˆ›å»ºè¯æ±‡è¡¨
    print("\nğŸš€ å¼€å§‹ç”Ÿæˆè¯æ±‡è¡¨...")
    print("   è¿™å¯èƒ½éœ€è¦10-30åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...")
    print()
    
    vocab = create_maritime_vocabulary(**config)
    
    print("\n" + "=" * 80)
    print("âœ… è¯æ±‡è¡¨ç”Ÿæˆå®Œæˆï¼")
    print("=" * 80)
    print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    print(f"   {config['output_path']}")
    print(f"\nğŸ¯ ä¸‹ä¸€æ­¥:")
    print(f"   è¿è¡Œè½¬æ¢è„šæœ¬:")
    print(f"   python convert_vocab_to_token.py \\")
    print(f"     --vocab {config['output_path']} \\")
    print(f"     --output smart/tokens/maritime_tokens_30s.pkl")
    print()

