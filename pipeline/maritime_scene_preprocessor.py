#!/usr/bin/env python3
"""
æµ·ä¸Šåœºæ™¯é¢„å¤„ç†å™¨
å°†åŸå§‹AISåœºæ™¯æ•°æ®è½¬æ¢ä¸ºSMARTæ¨¡å‹å¯ç”¨çš„æ ¼å¼
"""

import numpy as np
import pandas as pd
from scipy.interpolate import interp1d
import math
import torch
from torch_geometric.data import HeteroData
from typing import Tuple, List, Dict, Any

class MaritimeScenePreprocessor:
    
    def __init__(self, target_time_step: float = 30.0, num_historical_steps: int = 5,
                 apply_global_norm: bool = False, global_norm_stats_path: str = None,
                 verbose: bool = True):
        # æ³¨æ„ï¼šå¯¹é½Waymo - ä¸åœ¨é¢„å¤„ç†é˜¶æ®µå½’ä¸€åŒ–ï¼Œä¿æŒç±³åˆ¶å•ä½
        """
        åˆå§‹åŒ–é¢„å¤„ç†å™¨
        
        Args:
            target_time_step: ç›®æ ‡æ—¶é—´æ­¥é•¿(ç§’)ï¼Œé»˜è®¤30.0ç§’ï¼ˆåŒ¹é…åŸå§‹AISæ•°æ®ï¼‰
            num_historical_steps: å†å²æ­¥æ•° T_hï¼Œç”¨äºå®šä¹‰å±€éƒ¨åæ ‡å‚è€ƒå¸§ t_ref = T_h-1
        """
        self.target_time_step = target_time_step
        self.num_historical_steps = num_historical_steps
        self.apply_global_norm = apply_global_norm
        self.global_norm_stats = None
        self.verbose = verbose
        if global_norm_stats_path:
            try:
                import json
                with open(global_norm_stats_path, 'r') as f:
                    self.global_norm_stats = json.load(f)
            except Exception:
                self.global_norm_stats = None
    
    def lonlat_to_meter(self, lon: np.ndarray, lat: np.ndarray, 
                       origin_lon: float, origin_lat: float) -> Tuple[np.ndarray, np.ndarray]:
        """
        å°†ç»çº¬åº¦åæ ‡è½¬æ¢ä¸ºä»¥æŒ‡å®šåŸç‚¹ä¸ºåŸºå‡†çš„ç±³åˆ¶åæ ‡
        
        Args:
            lon: ç»åº¦æ•°ç»„
            lat: çº¬åº¦æ•°ç»„  
            origin_lon: åŸç‚¹ç»åº¦
            origin_lat: åŸç‚¹çº¬åº¦
            
        Returns:
            (x, y): ç±³åˆ¶åæ ‡æ•°ç»„
        """
        # åœ°çƒåŠå¾„ (ç±³)
        R = 6371000.0
        
        # è½¬æ¢ä¸ºå¼§åº¦
        lon_rad = np.radians(lon)
        lat_rad = np.radians(lat)
        origin_lon_rad = np.radians(origin_lon)
        origin_lat_rad = np.radians(origin_lat)
        
        # è®¡ç®—ç›¸å¯¹äºåŸç‚¹çš„ç±³åˆ¶åæ ‡
        # x = R * (lon - origin_lon) * cos(origin_lat)
        # y = R * (lat - origin_lat)
        x = R * (lon_rad - origin_lon_rad) * np.cos(origin_lat_rad)
        y = R * (lat_rad - origin_lat_rad)
        
        return x, y
    
    def resample_trajectory(self, traj_df: pd.DataFrame) -> pd.DataFrame:
        """
        å°†è½¨è¿¹é‡é‡‡æ ·åˆ°æŒ‡å®šæ—¶é—´é—´éš”
        
        Args:
            traj_df: åŸå§‹è½¨è¿¹DataFrame
            
        Returns:
            é‡é‡‡æ ·åçš„è½¨è¿¹DataFrame
        """
        # è½¬æ¢æ—¶é—´æˆ³ä¸ºç§’æ•°ï¼ˆç›¸å¯¹äºèµ·å§‹æ—¶é—´ï¼‰
        start_time = traj_df['timestamp'].iloc[0]
        traj_df = traj_df.copy()
        traj_df['time_seconds'] = (traj_df['timestamp'] - start_time).dt.total_seconds()
        
        # ç¡®å®šæ–°çš„æ—¶é—´ç‚¹
        max_time = traj_df['time_seconds'].max()
        # ç¡®ä¿è‡³å°‘åŒ…å«åŸå§‹æ•°æ®çš„æ—¶é—´èŒƒå›´
        new_time_points = np.arange(0, max_time + 0.1, self.target_time_step)  # æ·»åŠ å°çš„ç¼“å†²
        
        # å¯¹æ¯ä¸ªæ•°å€¼åˆ—è¿›è¡Œæ’å€¼
        interpolated_data = {'time_seconds': new_time_points}
        
        # å¤„ç†è§’åº¦æ•°æ®ï¼ˆèˆªå‘è§’ï¼‰éœ€è¦ç‰¹æ®Šå¤„ç†ï¼šå¯¹ cos/sin åˆ†é‡æ’å€¼ï¼Œå†ç”¨ atan2 åˆæˆ
        angle_columns = []
        if 'cog' in traj_df.columns:
            angle_columns.append(('cog', 'cog_rad'))  # å•ä½ï¼šåº¦ï¼ˆæ³¨æ„ï¼šå°†è½¬æ¢ä¸ºæ•°å­¦è§’ï¼‰
        if 'heading' in traj_df.columns:
            angle_columns.append(('heading', 'heading_rad'))  # å¯é€‰çš„é¢å¤–è§’åº¦åˆ—

        for deg_col, rad_out in angle_columns:
            angle_deg = traj_df[deg_col].values.astype(float)

            if deg_col == 'cog':
                # èˆªæµ·COG: åŒ—åŸº(0Â°å‘åŒ—)ã€é¡ºæ—¶é’ˆå¢
                # æ•°å­¦è§’: ä¸œåŸº(0Â°å‘ä¸œ)ã€é€†æ—¶é’ˆå¢
                # è½¬æ¢: theta_math = radians(90 - COG_deg)
                angle_math_rad = np.radians(90.0 - angle_deg)
                cos_val = np.cos(angle_math_rad)
                sin_val = np.sin(angle_math_rad)

                f_cos = interp1d(traj_df['time_seconds'].values, cos_val,
                                 kind='linear', bounds_error=False, fill_value='extrapolate')
                f_sin = interp1d(traj_df['time_seconds'].values, sin_val,
                                 kind='linear', bounds_error=False, fill_value='extrapolate')

                new_cos = f_cos(new_time_points)
                new_sin = f_sin(new_time_points)
                norm = np.hypot(new_cos, new_sin) + 1e-8
                new_cos /= norm
                new_sin /= norm

                new_theta_rad = np.arctan2(new_sin, new_cos)  # æ•°å­¦è§’ï¼ˆä¸œåŸºã€é€†æ—¶é’ˆï¼‰
                new_theta_deg = (np.degrees(new_theta_rad) + 360) % 360
                # åæ¨å›COGï¼ˆè‹¥éœ€è¦ä¿æŒå‡ºå‚çš„ä¸€è‡´æ€§ï¼‰ï¼šCOG_deg = 90 - theta_deg
                new_cog_deg = (90.0 - new_theta_deg) % 360

                # è¾“å‡ºï¼šæä¾› theta_radï¼ˆä¾›ä¸‹æ¸¸ä½¿ç”¨ï¼‰ï¼Œå¹¶ä¿ç•™ cogï¼ˆåº¦ï¼‰
                interpolated_data['theta_rad'] = new_theta_rad
                interpolated_data['theta_deg'] = new_theta_deg
                interpolated_data['cog'] = new_cog_deg
                # ä¸å†å†™å…¥ cog_radï¼Œé¿å…è¯¯ç”¨
            else:
                # å…¶ä»–è§’åº¦ï¼ˆå¦‚headingï¼‰ï¼Œé»˜è®¤å·²ä¸ºæ•°å­¦è§’ï¼ˆå¦‚ä¸æ˜¯è¯·æŒ‰éœ€æ±‚è½¬æ¢ï¼‰
                angle_rad = np.radians(angle_deg)
                cos_val = np.cos(angle_rad)
                sin_val = np.sin(angle_rad)

                f_cos = interp1d(traj_df['time_seconds'].values, cos_val,
                                 kind='linear', bounds_error=False, fill_value='extrapolate')
                f_sin = interp1d(traj_df['time_seconds'].values, sin_val,
                                 kind='linear', bounds_error=False, fill_value='extrapolate')

                new_cos = f_cos(new_time_points)
                new_sin = f_sin(new_time_points)
                norm = np.hypot(new_cos, new_sin) + 1e-8
                new_cos /= norm
                new_sin /= norm

                new_rad = np.arctan2(new_sin, new_cos)
                new_deg = (np.degrees(new_rad) + 360) % 360

                interpolated_data[deg_col] = new_deg
                interpolated_data[rad_out] = new_rad
        
        # å¯¹å…¶ä»–æ•°å€¼åˆ—è¿›è¡Œçº¿æ€§æ’å€¼
        numeric_columns = ['lon', 'lat', 'sog']
        for col in numeric_columns:
            if col in traj_df.columns:
                f = interp1d(traj_df['time_seconds'].values, traj_df[col].values, 
                           kind='linear', bounds_error=False, fill_value='extrapolate')
                interpolated_data[col] = f(new_time_points)
        
        # ä¿ç•™å…¶ä»–éæ•°å€¼åˆ—ï¼ˆå–ç¬¬ä¸€ä¸ªå€¼ï¼‰
        for col in ['mmsi']:
            if col in traj_df.columns:
                interpolated_data[col] = [traj_df[col].iloc[0]] * len(new_time_points)
        
        # é‡å»ºæ—¶é—´æˆ³
        interpolated_data['timestamp'] = [start_time + pd.Timedelta(seconds=t) for t in new_time_points]
        
        return pd.DataFrame(interpolated_data)
    
    def calculate_features(self, traj_df: pd.DataFrame, origin_lon: float, origin_lat: float) -> Dict[str, np.ndarray]:
        """
        è®¡ç®—è½¨è¿¹çš„å„ç§ç‰¹å¾
        
        Args:
            traj_df: é‡é‡‡æ ·åçš„è½¨è¿¹DataFrame
            origin_lon: åŸç‚¹ç»åº¦
            origin_lat: åŸç‚¹çº¬åº¦
            
        Returns:
            åŒ…å«æ‰€æœ‰ç‰¹å¾çš„å­—å…¸
        """
        # åæ ‡è½¬æ¢
        x, y = self.lonlat_to_meter(traj_df['lon'].values, traj_df['lat'].values, 
                                   origin_lon, origin_lat)
        
        # æ—¶é—´æ•°ç»„
        t = traj_df['time_seconds'].values
        dt = self.target_time_step
        
        # é€Ÿåº¦è®¡ç®— (m/s)
        # é¦–å…ˆä»SOGè½¬æ¢ (1èŠ‚ = 0.514444 m/s)
        sog_ms = traj_df['sog'].values * 0.514444
        
        # ğŸ”§ ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨SOGå’ŒCOGè®¡ç®—vx, vyï¼ˆæ›´å‡†ç¡®ï¼‰
        # COG/thetaè¡¨ç¤ºè¿åŠ¨æ–¹å‘
        if 'theta_rad' in traj_df.columns:
            theta = traj_df['theta_rad'].values
        elif 'cog_rad' in traj_df.columns:
            theta = traj_df['cog_rad'].values
        else:
            theta = np.arctan2(np.gradient(y, dt), np.gradient(x, dt))
        
        # ä»SOGå’Œæ–¹å‘è®¡ç®—vx, vy
        vx = sog_ms * np.cos(theta)  # ä½¿ç”¨SOGï¼Œè€Œä¸æ˜¯gradient
        vy = sog_ms * np.sin(theta)
        v_magnitude = sog_ms  # ç›´æ¥ä½¿ç”¨SOG
        
        # åŠ é€Ÿåº¦è®¡ç®— (m/sÂ²)
        ax = np.gradient(vx, dt)  # xæ–¹å‘åŠ é€Ÿåº¦
        ay = np.gradient(vy, dt)  # yæ–¹å‘åŠ é€Ÿåº¦
        a_magnitude = np.sqrt(ax**2 + ay**2)  # åŠ é€Ÿåº¦å¤§å°
        
        # èˆªå‘è§’å¤„ç†ï¼ˆä¼˜å…ˆä½¿ç”¨æ•°å­¦è§’ theta_radï¼Œå…¶æ¬¡é€€å› cog_radï¼Œæœ€åç”¨é€Ÿåº¦æ–¹å‘ï¼‰
        if 'theta_rad' in traj_df.columns:
            theta = traj_df['theta_rad'].values
        elif 'cog_rad' in traj_df.columns:
            theta = traj_df['cog_rad'].values
        else:
            # ä»é€Ÿåº¦æ–¹å‘è®¡ç®—èˆªå‘è§’
            theta = np.arctan2(vy, vx)
        
        # èˆªå‘å˜åŒ–ç‡ (rad/s)
        omega = np.gradient(theta, dt)
        
        # å¤„ç†è§’åº¦ä¸è¿ç»­æ€§
        omega = np.where(np.abs(omega) > np.pi/dt, 
                        omega - np.sign(omega) * 2 * np.pi / dt, 
                        omega)
        
        features = {
            'time_seconds': t,
            'x': x,
            'y': y, 
            'theta': theta,           # èˆªå‘è§’ (rad)
            'theta_deg': np.degrees(theta),  # èˆªå‘è§’ (åº¦)
            'vx': vx,                # xæ–¹å‘é€Ÿåº¦ (m/s)
            'vy': vy,                # yæ–¹å‘é€Ÿåº¦ (m/s) 
            'v_magnitude': v_magnitude,      # é€Ÿåº¦å¤§å° (m/s)
            'sog_ms': sog_ms,        # åŸå§‹SOGè½¬æ¢çš„é€Ÿåº¦ (m/s)
            'ax': ax,                # xæ–¹å‘åŠ é€Ÿåº¦ (m/sÂ²)
            'ay': ay,                # yæ–¹å‘åŠ é€Ÿåº¦ (m/sÂ²)
            'a_magnitude': a_magnitude,      # åŠ é€Ÿåº¦å¤§å° (m/sÂ²)
            'omega': omega,          # èˆªå‘å˜åŒ–ç‡ (rad/s)
            'mmsi': traj_df['mmsi'].values[0]  # èˆ¹åªæ ‡è¯†
        }
        
        return features

    def wrap_angle_rad(self, angle: np.ndarray) -> np.ndarray:
        """å°†è§’åº¦å½’ä¸€åŒ–åˆ°(-pi, pi]åŒºé—´"""
        return (angle + np.pi) % (2 * np.pi) - np.pi

    def to_local_at_hist_end(self, features: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:
        """
        å°†å…¨å±€ç‰¹å¾è½¬æ¢åˆ°ä»¥å†å²ç»“æŸå¸§ T_h-1 ä¸ºåŸç‚¹ä¸æœå‘çš„å±€éƒ¨åæ ‡ç³»ã€‚
        ä½¿å¾—åœ¨ t_ref (T_h-1) æ—¶åˆ»æ»¡è¶³: x'=0, y'=0, theta'=0ã€‚
        """
        # å‚è€ƒå¸§ï¼šå†å²ç»“æŸå¸§
        t_ref = int(min(self.num_historical_steps - 1, len(features['time_seconds']) - 1))
        theta_ref = float(features['theta'][t_ref])
        cos_t = np.cos(theta_ref)
        sin_t = np.sin(theta_ref)

        # å¹³ç§»è‡³å‚è€ƒç‚¹
        dx = features['x'] - float(features['x'][t_ref])
        dy = features['y'] - float(features['y'][t_ref])

        # æ—‹è½¬åˆ°å‚è€ƒæœå‘ï¼ˆä½¿å‚è€ƒå¸§æœå‘ä¸º0ï¼‰
        x_local =  cos_t * dx + sin_t * dy
        y_local = -sin_t * dx + cos_t * dy

        vx_local =  cos_t * features['vx'] + sin_t * features['vy']
        vy_local = -sin_t * features['vx'] + cos_t * features['vy']

        ax_local =  cos_t * features['ax'] + sin_t * features['ay']
        ay_local = -sin_t * features['ax'] + cos_t * features['ay']

        theta_local = self.wrap_angle_rad(features['theta'] - theta_ref)
        omega = features['omega']  # å¸¸é‡åç§»ä¸æ”¹å˜è§’é€Ÿåº¦

        return {
            'time_seconds': features['time_seconds'],
            'x': x_local,
            'y': y_local,
            'vx': vx_local,
            'vy': vy_local,
            'ax': ax_local,
            'ay': ay_local,
            'v_magnitude': features.get('v_magnitude', np.sqrt(vx_local ** 2 + vy_local ** 2)),
            'a_magnitude': features.get('a_magnitude', np.sqrt(ax_local ** 2 + ay_local ** 2)),
            'theta': theta_local,
            'theta_deg': np.degrees(theta_local),
            'omega': omega,
            'mmsi': features['mmsi']
        }

    def to_local_at_t_ref(self, features: Dict[str, np.ndarray], t_ref: int) -> Dict[str, np.ndarray]:
        """
        åŸºäºä»»æ„å‚è€ƒå¸§ t_ref å°†å…¨å±€ç‰¹å¾è½¬æ¢è‡³å±€éƒ¨åæ ‡ï¼ˆx'=0,y'=0,theta'=0 at t_refï¼‰ã€‚
        """
        t_ref = int(max(0, min(t_ref, len(features['time_seconds']) - 1)))
        theta_ref = float(features['theta'][t_ref])
        cos_t = np.cos(theta_ref)
        sin_t = np.sin(theta_ref)

        dx = features['x'] - float(features['x'][t_ref])
        dy = features['y'] - float(features['y'][t_ref])

        x_local =  cos_t * dx + sin_t * dy
        y_local = -sin_t * dx + cos_t * dy

        vx_local =  cos_t * features['vx'] + sin_t * features['vy']
        vy_local = -sin_t * features['vx'] + cos_t * features['vy']

        ax_local =  cos_t * features['ax'] + sin_t * features['ay']
        ay_local = -sin_t * features['ax'] + cos_t * features['ay']

        theta_local = self.wrap_angle_rad(features['theta'] - theta_ref)
        omega = features['omega']

        return {
            'time_seconds': features['time_seconds'],
            'x': x_local,
            'y': y_local,
            'vx': vx_local,
            'vy': vy_local,
            'ax': ax_local,
            'ay': ay_local,
            'v_magnitude': features.get('v_magnitude', np.sqrt(vx_local ** 2 + vy_local ** 2)),
            'a_magnitude': features.get('a_magnitude', np.sqrt(ax_local ** 2 + ay_local ** 2)),
            'theta': theta_local,
            'theta_deg': np.degrees(theta_local),
            'omega': omega,
            'mmsi': features['mmsi']
        }

    def generate_window_indices(self, total_steps: int, num_historical_steps: int, num_future_steps: int,
                                stride: int = 1) -> List[Dict[str, int]]:
        """
        ç”Ÿæˆæ»‘åŠ¨çª—å£çš„ç´¢å¼•åˆ—è¡¨ã€‚
        è¿”å›çš„æ¯ä¸ªå…ƒç´ åŒ…å«ï¼šhist_start, hist_end(=t_ref), fut_endï¼ˆä¸å«ï¼‰
        """
        windows = []
        if total_steps < (num_historical_steps + num_future_steps):
            return windows
        # t_ref æ˜¯å†å²ç»“æŸå¸§ç´¢å¼•
        t_ref_start = num_historical_steps - 1
        t_ref_end = total_steps - num_future_steps - 1
        for t_ref in range(t_ref_start, t_ref_end + 1, stride):
            hist_start = t_ref - (num_historical_steps - 1)
            hist_end = t_ref
            fut_end = t_ref + num_future_steps + 1  # å³å¼€åŒºé—´
            windows.append({'hist_start': hist_start, 'hist_end': hist_end, 'fut_end': fut_end})
        return windows

    def create_hetero_data_for_window(self, processed_scene: Dict[str, Any],
                                      hist_start: int, hist_end: int, fut_end: int) -> HeteroData:
        """
        åŸºäºå•ä¸ªæ»‘åŠ¨çª—å£æ„å»º HeteroDataï¼š
        - ä½¿ç”¨å±€éƒ¨åæ ‡ï¼ˆå‚è€ƒå¸§ = hist_endï¼Œæ‰€æœ‰èˆ¹ç›¸å¯¹äºç¬¬ä¸€è‰˜èˆ¹ï¼‰
        - æ„é€ è¾“å…¥åºåˆ— = å†å² + æœªæ¥ï¼ˆæ€»å¸§æ•° = fut_end - hist_startï¼‰
        - é¢å¤–æä¾› mask ä¸æœªæ¥ç›®æ ‡åæ ‡ï¼Œä¾¿äºè®­ç»ƒ
        """
        ships = processed_scene['ships']
        impacts = processed_scene['impacts']
        ship_features_global = [ship['features_global'] for ship in ships]
        num_ships = len(ships)
        num_hist = hist_end - hist_start + 1
        num_future = fut_end - hist_end - 1
        total_steps = fut_end - hist_start

        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ç»Ÿä¸€çš„å‚è€ƒç‚¹ï¼ˆç¬¬ä¸€è‰˜èˆ¹åœ¨hist_endçš„ä½ç½®å’Œæœå‘ï¼‰
        # è€Œä¸æ˜¯è®©æ¯è‰˜èˆ¹ä»¥è‡ªå·±ä¸ºåŸç‚¹ï¼
        reference_ship = ship_features_global[0]  # av_index = 0
        t_ref = hist_end
        theta_ref = float(reference_ship['theta'][t_ref])
        x_ref = float(reference_ship['x'][t_ref])
        y_ref = float(reference_ship['y'][t_ref])
        cos_t = np.cos(theta_ref)
        sin_t = np.sin(theta_ref)

        # è®¡ç®—çª—å£å‚è€ƒå¸§çš„çœŸå®ç»çº¬åº¦ï¼ˆåŸºäºåœºæ™¯åŸç‚¹åæ¨ï¼‰
        R = 6371000.0
        origin_lat = float(processed_scene['metadata']['origin_lat'])
        origin_lon = float(processed_scene['metadata']['origin_lon'])
        origin_lat_rad = np.radians(origin_lat)

        ref_lat = origin_lat + np.degrees(y_ref / R)
        ref_lon = origin_lon + np.degrees(x_ref / (R * np.cos(origin_lat_rad)))

        # è®¡ç®—å±€éƒ¨ç‰¹å¾ï¼ˆæ‰€æœ‰èˆ¹ç›¸å¯¹äºç»Ÿä¸€å‚è€ƒç‚¹ï¼‰å¹¶è£å‰ªåˆ°çª—å£åŒºé—´
        agent_features = []
        target_xy = []
        is_history_mask = np.zeros((num_ships, total_steps), dtype=bool)
        for s in range(num_ships):
            feats_g = ship_features_global[s]
            
            # è½¬æ¢åˆ°ç»Ÿä¸€çš„å±€éƒ¨åæ ‡ç³»ï¼ˆç›¸å¯¹äºå‚è€ƒèˆ¹ï¼‰
            dx = feats_g['x'] - x_ref
            dy = feats_g['y'] - y_ref
            x_local =  cos_t * dx + sin_t * dy
            y_local = -sin_t * dx + cos_t * dy
            
            vx_local =  cos_t * feats_g['vx'] + sin_t * feats_g['vy']
            vy_local = -sin_t * feats_g['vx'] + cos_t * feats_g['vy']
            
            ax_local =  cos_t * feats_g['ax'] + sin_t * feats_g['ay']
            ay_local = -sin_t * feats_g['ax'] + cos_t * feats_g['ay']
            
            theta_local = self.wrap_angle_rad(feats_g['theta'] - theta_ref)
            omega_local = feats_g['omega']  # è§’é€Ÿåº¦ä¸å—åæ ‡ç³»å¹³ç§»å’Œæ—‹è½¬å½±å“
            
            # åˆ‡ç‰‡çª—å£ï¼ˆä½¿ç”¨æ–°è®¡ç®—çš„å±€éƒ¨åæ ‡ï¼‰
            x_arr = x_local[hist_start:fut_end]
            y_arr = y_local[hist_start:fut_end]
            vx_arr = vx_local[hist_start:fut_end]
            vy_arr = vy_local[hist_start:fut_end]
            ax_arr = ax_local[hist_start:fut_end]
            ay_arr = ay_local[hist_start:fut_end]
            theta_arr = theta_local[hist_start:fut_end]
            omega_arr = omega_local[hist_start:fut_end]

            # ========== å½’ä¸€åŒ–å·²ç¦ç”¨ï¼ˆå¯¹é½Waymoï¼‰==========
            # Waymoä¸åœ¨é¢„å¤„ç†æ—¶å½’ä¸€åŒ–ï¼Œä¿æŒç±³åˆ¶å•ä½(m, m/s)
            if False:  # self.apply_global_norm and self.global_norm_stats is not None:
                def norm_arr(key, arr):
                    stats = self.global_norm_stats.get(key, None)
                    if stats is None:
                        return arr
                    mean, std = float(stats['mean']), float(stats['std']) + 1e-8
                    return (arr - mean) / std
                x_arr  = norm_arr('x',  x_arr)
                y_arr  = norm_arr('y',  y_arr)
                vx_arr = norm_arr('vx', vx_arr)
                vy_arr = norm_arr('vy', vy_arr)
                ax_arr = norm_arr('ax', ax_arr)
                ay_arr = norm_arr('ay', ay_arr)
                theta_arr = norm_arr('theta', theta_arr)
                omega_arr = norm_arr('omega', omega_arr)

            ship_matrix = np.stack([x_arr, y_arr, vx_arr, vy_arr, ax_arr, ay_arr, theta_arr, omega_arr], axis=1)
            agent_features.append(ship_matrix)

            # æœªæ¥ç›®æ ‡ï¼ˆæœªå½’ä¸€åŒ–ï¼Œä½¿ç”¨å±€éƒ¨åæ ‡åŸå€¼ï¼Œç›¸å¯¹äºç»Ÿä¸€å‚è€ƒç‚¹ï¼‰
            target_xy.append(
                np.stack([
                    x_local[hist_end+1:fut_end],
                    y_local[hist_end+1:fut_end]
                ], axis=1)
            )
            is_history_mask[s, :num_hist] = True

        agent_features = np.stack(agent_features, axis=0)  # [N, total_steps, F]
        target_xy = np.stack(target_xy, axis=0)            # [N, num_future, 2]

        # è¾¹å…³ç³»ï¼ˆåœ¨å…¨å±€åæ ‡ç³»çš„ hist_end å¸§è¯„ä¼°ï¼‰
        edge_indices = self.build_graph_edges(ship_features_global, impacts, t_ref=hist_end)

        data = HeteroData()
        data['agent'].x = torch.tensor(agent_features, dtype=torch.float32)
        data['agent'].num_nodes = num_ships
        data['agent'].valid_mask = torch.ones(num_ships, total_steps, dtype=torch.bool)
        data['agent'].is_history_mask = torch.tensor(is_history_mask, dtype=torch.bool)
        data['agent'].target_xy = torch.tensor(target_xy, dtype=torch.float32)
        data['agent'].type = torch.zeros(num_ships, dtype=torch.long)
        data['agent'].av_index = torch.tensor(0, dtype=torch.long)
        data['agent'].mmsi = torch.tensor([ship['mmsi'] for ship in ships], dtype=torch.long)

        if edge_indices['interaction_edges'].numel() > 0:
            data['agent', 'interacts_with', 'agent'].edge_index = edge_indices['interaction_edges']
        if edge_indices['proximity_edges'].numel() > 0:
            data['agent', 'near_to', 'agent'].edge_index = edge_indices['proximity_edges']

        data.metadata = {
            **processed_scene['metadata'],
            'hist_start': hist_start,
            'hist_end': hist_end,
            'fut_end': fut_end,
            'num_hist': num_hist,
            'num_future': num_future
        }
        data.original_impacts = torch.tensor(impacts, dtype=torch.float32)

        data.scene_info = {
            'ref_lat': float(ref_lat),
            'ref_lon': float(ref_lon),
            'ref_theta': float(theta_ref)
        }

        return data

    def create_hetero_data_windows(self, processed_scene: Dict[str, Any],
                                   num_historical_steps: int, num_future_steps: int,
                                   stride: int = 1) -> List[HeteroData]:
        """
        ä¸ºä¸€ä¸ªåœºæ™¯ç”Ÿæˆå¤šä¸ªæ»‘åŠ¨çª—å£çš„ HeteroData æ ·æœ¬ã€‚
        """
        total_steps = processed_scene['metadata']['time_steps']
        windows = self.generate_window_indices(total_steps, num_historical_steps, num_future_steps, stride)
        samples = []
        for w in windows:
            data = self.create_hetero_data_for_window(processed_scene, w['hist_start'], w['hist_end'], w['fut_end'])
            samples.append(data)
        return samples
    
    def normalize_features(self, all_ship_features: List[Dict[str, np.ndarray]]) -> Tuple[Dict[str, np.ndarray], Dict[str, Dict[str, float]]]:
        """
        å¯¹æ‰€æœ‰èˆ¹åªçš„ç‰¹å¾è¿›è¡Œå½’ä¸€åŒ–
        
        Args:
            all_ship_features: æ‰€æœ‰èˆ¹åªçš„ç‰¹å¾åˆ—è¡¨
            
        Returns:
            (normalized_features, normalization_stats): å½’ä¸€åŒ–åçš„ç‰¹å¾å’Œç»Ÿè®¡ä¿¡æ¯
        """
        # è¯´æ˜ï¼šSMARTèŒƒå¼è¦æ±‚åœ¨å±€éƒ¨åæ ‡ç³»ä¸‹å·¥ä½œï¼Œä¸€èˆ¬ä¸å¯¹å‡ ä½•ç‰¹å¾åšå…¨å±€Z-scoreã€‚
        # å‡ºäºè°ƒè¯•å¯è§†åŒ–ä¹‹ç”¨ï¼Œæ­¤å‡½æ•°ä¿ç•™ï¼Œä½†ä¸åœ¨HeteroDataä¸­åº”ç”¨å…¶ç»“æœã€‚
        # æ”¶é›†æ‰€æœ‰èˆ¹åªçš„ç‰¹å¾ç”¨äºè®¡ç®—å…¨å±€ç»Ÿè®¡
        all_features = {}
        feature_keys = ['x', 'y', 'vx', 'vy', 'v_magnitude', 'ax', 'ay', 'a_magnitude', 'theta', 'omega']
        
        for key in feature_keys:
            all_values = []
            for ship_features in all_ship_features:
                if key in ship_features:
                    all_values.extend(ship_features[key].flatten())
            all_features[key] = np.array(all_values)
        
        # è®¡ç®—å½’ä¸€åŒ–ç»Ÿè®¡ä¿¡æ¯
        normalization_stats = {}
        for key, values in all_features.items():
            normalization_stats[key] = {
                'mean': float(np.mean(values)),
                'std': float(np.std(values)) + 1e-8,  # é¿å…é™¤é›¶
                'min': float(np.min(values)),
                'max': float(np.max(values))
            }
        
        # å½’ä¸€åŒ–æ¯è‰˜èˆ¹çš„ç‰¹å¾
        normalized_ships = []
        for ship_features in all_ship_features:
            normalized_ship = {}
            for key, values in ship_features.items():
                if key in normalization_stats:
                    # Z-scoreå½’ä¸€åŒ–
                    normalized_ship[key] = (values - normalization_stats[key]['mean']) / normalization_stats[key]['std']
                else:
                    # éæ•°å€¼ç‰¹å¾ä¿æŒä¸å˜
                    normalized_ship[key] = values
            normalized_ships.append(normalized_ship)
        
        return normalized_ships, normalization_stats
    
    def build_graph_edges(self, ship_features_global: List[Dict[str, np.ndarray]], 
                         impacts: np.ndarray,
                         t_ref: int,
                         distance_threshold: float = 1000.0) -> Dict[str, torch.Tensor]:
        """
        æ„å»ºå›¾çš„è¾¹å…³ç³»
        
        Args:
            ship_features_global: èˆ¹åªå…¨å±€ç‰¹å¾åˆ—è¡¨(ç”¨äºè·ç¦»è®¡ç®—)
            impacts: å½±å“çŸ©é˜µ
            t_ref: é‚»è¿‘è¯„ä¼°å‚è€ƒå¸§ï¼ˆå†å²ç»“æŸå¸§ï¼‰
            distance_threshold: è·ç¦»é˜ˆå€¼(ç±³)
            
        Returns:
            è¾¹ç´¢å¼•å­—å…¸
        """
        num_ships = len(ship_features_global)
        
        # åŸºäºimpactsçŸ©é˜µçš„äº¤äº’è¾¹
        interaction_edges = []
        for i in range(num_ships):
            for j in range(num_ships):
                if i != j and impacts[i, j] > 0:
                    interaction_edges.append([i, j])
        
        # åŸºäºè·ç¦»çš„é‚»è¿‘è¾¹ï¼ˆä»…åœ¨å‚è€ƒå¸§ t_ref è¿›è¡Œè¯„ä¼°ï¼‰
        proximity_edges = []
        for i in range(num_ships):
            for j in range(i + 1, num_ships):
                dx = ship_features_global[i]['x'][t_ref] - ship_features_global[j]['x'][t_ref]
                dy = ship_features_global[i]['y'][t_ref] - ship_features_global[j]['y'][t_ref]
                distance = np.sqrt(dx**2 + dy**2)
                if distance < distance_threshold:
                    proximity_edges.append([i, j])
                    proximity_edges.append([j, i])  # æ— å‘è¾¹
        
        # å»é‡é‚»è¿‘è¾¹
        proximity_edges = list(set([tuple(edge) for edge in proximity_edges]))
        proximity_edges = [list(edge) for edge in proximity_edges]
        
        edge_indices = {
            'interaction_edges': torch.tensor(interaction_edges).t().contiguous() if interaction_edges else torch.empty((2, 0), dtype=torch.long),
            'proximity_edges': torch.tensor(proximity_edges).t().contiguous() if proximity_edges else torch.empty((2, 0), dtype=torch.long)
        }
        
        return edge_indices
    
    def create_hetero_data(self, processed_scene: Dict[str, Any]) -> HeteroData:
        """
        åˆ›å»ºPyTorch Geometric HeteroDataç»“æ„
        
        Args:
            processed_scene: é¢„å¤„ç†åçš„åœºæ™¯æ•°æ®
            
        Returns:
            HeteroDataå¯¹è±¡
        """
        ships = processed_scene['ships']
        impacts = processed_scene['impacts']
        metadata = processed_scene['metadata']

        # æå–å±€éƒ¨ä¸å…¨å±€ç‰¹å¾
        ship_features_local = [ship['features_local'] for ship in ships]
        ship_features_global = [ship['features_global'] for ship in ships]

        # æ„å»ºèŠ‚ç‚¹ç‰¹å¾å¼ é‡ï¼ˆä½¿ç”¨å±€éƒ¨åæ ‡ç³»ç‰¹å¾ï¼‰ï¼Œå¹¶åœ¨éœ€è¦æ—¶åº”ç”¨å…¨å±€å½’ä¸€åŒ–
        num_ships = len(ships)
        num_timesteps = len(ship_features_local[0]['time_seconds'])

        agent_features = []
        for ship_data in ship_features_local:
            # ========== å½’ä¸€åŒ–å·²ç¦ç”¨ï¼ˆå¯¹é½Waymoï¼‰==========
            # Waymoä¸åœ¨é¢„å¤„ç†æ—¶å½’ä¸€åŒ–ï¼Œä¿æŒç±³åˆ¶å•ä½(m, m/s)
            if False:  # self.apply_global_norm and self.global_norm_stats is not None:
                # ä½¿ç”¨å›ºå®šçš„å…¨å±€å‡å€¼/æ ‡å‡†å·®
                def norm_arr(key, arr):
                    stats = self.global_norm_stats.get(key, None)
                    if stats is None:
                        return arr
                    mean, std = float(stats['mean']), float(stats['std']) + 1e-8
                    return (arr - mean) / std
                x_arr  = norm_arr('x',  ship_data['x'])
                y_arr  = norm_arr('y',  ship_data['y'])
                vx_arr = norm_arr('vx', ship_data['vx'])
                vy_arr = norm_arr('vy', ship_data['vy'])
                ax_arr = norm_arr('ax', ship_data['ax'])
                ay_arr = norm_arr('ay', ship_data['ay'])
                theta_arr = norm_arr('theta', ship_data['theta'])
                omega_arr = norm_arr('omega', ship_data['omega'])
            else:
                x_arr, y_arr = ship_data['x'], ship_data['y']
                vx_arr, vy_arr = ship_data['vx'], ship_data['vy']
                ax_arr, ay_arr = ship_data['ax'], ship_data['ay']
                theta_arr, omega_arr = ship_data['theta'], ship_data['omega']
            ship_feature_matrix = np.stack([
                x_arr,
                y_arr, 
                vx_arr,
                vy_arr,
                ax_arr,
                ay_arr,
                theta_arr,
                omega_arr
            ], axis=1)
            agent_features.append(ship_feature_matrix)

        agent_features = np.stack(agent_features, axis=0)

        # æ„å»ºè¾¹å…³ç³»ï¼šåœ¨å…¨å±€åæ ‡ç³»çš„å†å²ç»“æŸå¸§è¯„ä¼°é‚»è¿‘å…³ç³»
        t_ref = int(min(self.num_historical_steps - 1, num_timesteps - 1))
        edge_indices = self.build_graph_edges(ship_features_global, impacts, t_ref)
        
        # åˆ›å»ºHeteroData
        data = HeteroData()
        
        # AgentèŠ‚ç‚¹æ•°æ®
        data['agent'].x = torch.tensor(agent_features, dtype=torch.float32)
        data['agent'].num_nodes = num_ships
        
        # Agentç±»å‹ä¿¡æ¯ (æµ·ä¸Šåœºæ™¯ä¸­æ‰€æœ‰éƒ½æ˜¯èˆ¹åªï¼Œç±»å‹è®¾ä¸º0)
        data['agent'].type = torch.zeros(num_ships, dtype=torch.long)
        
        # æœ‰æ•ˆæ€§æ©ç  (ç®€åŒ–ï¼šæ‰€æœ‰æ—¶é—´æ­¥éƒ½æœ‰æ•ˆ)
        data['agent'].valid_mask = torch.ones(num_ships, num_timesteps, dtype=torch.bool)
        
        # AVç´¢å¼• (é€‰æ‹©ç¬¬ä¸€è‰˜èˆ¹ä½œä¸ºå…³æ³¨å¯¹è±¡)
        data['agent'].av_index = torch.tensor(0, dtype=torch.long)
        
        # èˆ¹åªID
        data['agent'].mmsi = torch.tensor([ship['mmsi'] for ship in ships], dtype=torch.long)
        
        # è¾¹å…³ç³»
        if edge_indices['interaction_edges'].numel() > 0:
            data['agent', 'interacts_with', 'agent'].edge_index = edge_indices['interaction_edges']
        
        if edge_indices['proximity_edges'].numel() > 0:
            data['agent', 'near_to', 'agent'].edge_index = edge_indices['proximity_edges']
        
        # æ·»åŠ å…ƒæ•°æ®
        data.metadata = metadata
        data.original_impacts = torch.tensor(impacts, dtype=torch.float32)
        
        return data
    
    def validate_hetero_data(self, data: HeteroData) -> Dict[str, Any]:
        """
        éªŒè¯HeteroDataç»“æ„
        
        Args:
            data: HeteroDataå¯¹è±¡
            
        Returns:
            éªŒè¯ç»“æœå­—å…¸
        """
        validation_results = {
            'structure_valid': True,
            'errors': [],
            'warnings': [],
            'statistics': {}
        }
        
        try:
            # éªŒè¯èŠ‚ç‚¹æ•°æ®
            if 'agent' in data:
                agent_data = data['agent']
                num_ships, num_timesteps, num_features = agent_data.x.shape
                
                validation_results['statistics'].update({
                    'num_ships': num_ships,
                    'num_timesteps': num_timesteps,
                    'num_features': num_features,
                    'agent_features_shape': list(agent_data.x.shape),
                    'agent_features_dtype': str(agent_data.x.dtype)
                })
                
                # æ£€æŸ¥ç‰¹å¾æ˜¯å¦åŒ…å«NaNæˆ–Inf
                if torch.isnan(agent_data.x).any():
                    validation_results['errors'].append("Agent features contain NaN values")
                    validation_results['structure_valid'] = False
                
                if torch.isinf(agent_data.x).any():
                    validation_results['errors'].append("Agent features contain Inf values")
                    validation_results['structure_valid'] = False
                
                # æ£€æŸ¥valid_mask
                if hasattr(agent_data, 'valid_mask'):
                    if agent_data.valid_mask.shape != (num_ships, num_timesteps):
                        validation_results['errors'].append(f"Valid mask shape mismatch: {agent_data.valid_mask.shape} vs expected ({num_ships}, {num_timesteps})")
                        validation_results['structure_valid'] = False
                
            # éªŒè¯è¾¹æ•°æ®
            edge_types = []
            for edge_type in data.edge_types:
                edge_data = data[edge_type]
                edge_index = edge_data.edge_index
                num_edges = edge_index.shape[1]
                edge_types.append({
                    'type': str(edge_type),
                    'num_edges': num_edges,
                    'shape': list(edge_index.shape)
                })
            
            validation_results['statistics']['edge_types'] = edge_types
            
            # æ£€æŸ¥ç‰¹å¾ç»Ÿè®¡
            if 'agent' in data:
                features = data['agent'].x
                validation_results['statistics']['feature_stats'] = {
                    'mean': features.mean(dim=(0,1)).tolist(),
                    'std': features.std(dim=(0,1)).tolist(),
                    'min': features.min().item(),
                    'max': features.max().item()
                }
            
        except Exception as e:
            validation_results['structure_valid'] = False
            validation_results['errors'].append(f"Validation error: {str(e)}")
        
        return validation_results
    
    def print_hetero_data_info(self, data: HeteroData):
        """æ‰“å°HeteroDataçš„è¯¦ç»†ç»“æ„ä¿¡æ¯"""
        print(f"\nğŸ” HeteroDataè¯¦ç»†ç»“æ„ä¿¡æ¯:")
        
        # èŠ‚ç‚¹ç±»å‹
        print(f"   èŠ‚ç‚¹ç±»å‹: {list(data.node_types)}")
        
        # è¾¹ç±»å‹  
        if len(data.edge_types) > 0:
            print(f"   è¾¹ç±»å‹: {list(data.edge_types)}")
        else:
            print(f"   è¾¹ç±»å‹: æ— ")
        
        # AgentèŠ‚ç‚¹è¯¦æƒ…
        if 'agent' in data:
            agent_data = data['agent']
            print(f"\n   AgentèŠ‚ç‚¹è¯¦æƒ…:")
            for key, value in agent_data.items():
                if isinstance(value, torch.Tensor):
                    print(f"     {key}: {value.shape} ({value.dtype})")
                else:
                    print(f"     {key}: {value} ({type(value).__name__})")
        
        # è¾¹è¯¦æƒ…
        for edge_type in data.edge_types:
            edge_data = data[edge_type]
            print(f"\n   è¾¹ {edge_type} è¯¦æƒ…:")
            for key, value in edge_data.items():
                if isinstance(value, torch.Tensor):
                    print(f"     {key}: {value.shape} ({value.dtype})")
                else:
                    print(f"     {key}: {value} ({type(value).__name__})")
        
        # é™„åŠ å±æ€§
        extra_attrs = []
        for key in data.keys():
            if key not in data.node_types and key not in [str(et) for et in data.edge_types]:
                extra_attrs.append(key)
        
        if extra_attrs:
            print(f"\n   é¢å¤–å±æ€§: {extra_attrs}")
    
    def preprocess_scene(self, scene_data: Tuple[List[pd.DataFrame], np.ndarray]) -> Dict[str, Any]:
        """
        é¢„å¤„ç†å•ä¸ªåœºæ™¯æ•°æ®
        
        Args:
            scene_data: (trajectories, impacts) å…ƒç»„
            
        Returns:
            é¢„å¤„ç†åçš„åœºæ™¯æ•°æ®å­—å…¸
        """
        trajectories, impacts = scene_data
        
        if self.verbose:
            print(f"å¼€å§‹é¢„å¤„ç†åœºæ™¯ï¼š{len(trajectories)}è‰˜èˆ¹åª")
        
        # ç¡®å®šåŸç‚¹ï¼šç¬¬ä¸€è‰˜èˆ¹çš„ç¬¬ä¸€ä¸ªæ—¶é—´ç‚¹
        origin_traj = trajectories[0]
        origin_lon = origin_traj['lon'].iloc[0]
        origin_lat = origin_traj['lat'].iloc[0]
        origin_time = origin_traj['timestamp'].iloc[0]
        
        if self.verbose:
            print(f"åŸç‚¹è®¾ç½®: ({origin_lon:.6f}, {origin_lat:.6f}) at {origin_time}")
        
        # å¤„ç†æ¯è‰˜èˆ¹çš„è½¨è¿¹
        processed_ships = []
        all_features_global = []
        
        for i, traj in enumerate(trajectories):
            if self.verbose:
                print(f"å¤„ç†èˆ¹åª {i+1}/{len(trajectories)}: MMSI={traj['mmsi'].iloc[0]}")
            
            # æ—¶é—´é‡é‡‡æ ·
            resampled_traj = self.resample_trajectory(traj)
            
            # ç‰¹å¾è®¡ç®—ï¼ˆå…¨å±€ï¼‰
            features_global = self.calculate_features(resampled_traj, origin_lon, origin_lat)
            all_features_global.append(features_global)
            
            processed_ships.append({
                'ship_id': i,
                'mmsi': features_global['mmsi'],
                'features_global': features_global,
                'original_length': len(traj),
                'resampled_length': len(resampled_traj)
            })
        
        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ç»Ÿä¸€çš„å‚è€ƒç‚¹ï¼ˆç¬¬ä¸€è‰˜èˆ¹ï¼‰è®¡ç®—å±€éƒ¨åæ ‡
        # è€Œä¸æ˜¯è®©æ¯è‰˜èˆ¹ä»¥è‡ªå·±ä¸ºåŸç‚¹
        if len(all_features_global) > 0:
            reference_ship = all_features_global[0]
            t_ref = min(self.num_historical_steps - 1, len(reference_ship['time_seconds']) - 1)
            theta_ref = float(reference_ship['theta'][t_ref])
            x_ref = float(reference_ship['x'][t_ref])
            y_ref = float(reference_ship['y'][t_ref])
            cos_t = np.cos(theta_ref)
            sin_t = np.sin(theta_ref)
            
            for i, ship in enumerate(processed_ships):
                feats_g = all_features_global[i]
                
                # è½¬æ¢åˆ°ç»Ÿä¸€çš„å±€éƒ¨åæ ‡ç³»ï¼ˆç›¸å¯¹äºå‚è€ƒèˆ¹ï¼‰
                dx = feats_g['x'] - x_ref
                dy = feats_g['y'] - y_ref
                x_local =  cos_t * dx + sin_t * dy
                y_local = -sin_t * dx + cos_t * dy
                
                vx_local =  cos_t * feats_g['vx'] + sin_t * feats_g['vy']
                vy_local = -sin_t * feats_g['vx'] + cos_t * feats_g['vy']
                
                ax_local =  cos_t * feats_g['ax'] + sin_t * feats_g['ay']
                ay_local = -sin_t * feats_g['ax'] + cos_t * feats_g['ay']
                
                theta_local = self.wrap_angle_rad(feats_g['theta'] - theta_ref)
                omega_local = feats_g['omega']
                
                features_local = {
                    'time_seconds': feats_g['time_seconds'],
                    'x': x_local,
                    'y': y_local,
                    'vx': vx_local,
                    'vy': vy_local,
                    'ax': ax_local,
                    'ay': ay_local,
                    'v_magnitude': feats_g.get('v_magnitude', np.sqrt(vx_local ** 2 + vy_local ** 2)),
                    'a_magnitude': feats_g.get('a_magnitude', np.sqrt(ax_local ** 2 + ay_local ** 2)),
                    'theta': theta_local,
                    'theta_deg': np.degrees(theta_local),
                    'omega': omega_local,
                    'mmsi': feats_g['mmsi']
                }
                
                ship['features_local'] = features_local
        
        # ç»Ÿè®¡ä¿¡æ¯
        time_steps = len(processed_ships[0]['features_local']['time_seconds'])
        
        # æ„å»ºç»“æœ
        result = {
            'metadata': {
                'ship_count': len(trajectories),
                'time_steps': time_steps,
                'time_step_size': self.target_time_step,
                'origin_lon': origin_lon,
                'origin_lat': origin_lat,
                'origin_time': origin_time,
                'total_duration': (time_steps - 1) * self.target_time_step
            },
            'ships': processed_ships,
            'impacts': impacts,
            'original_impacts_shape': impacts.shape
        }
        
        if self.verbose:
            print(f"é¢„å¤„ç†å®Œæˆï¼š{len(processed_ships)}è‰˜èˆ¹åªï¼Œ{time_steps}ä¸ªæ—¶é—´æ­¥")
        
        return result
    
    def print_scene_summary(self, processed_scene: Dict[str, Any]):
        """æ‰“å°é¢„å¤„ç†ååœºæ™¯çš„æ‘˜è¦ä¿¡æ¯"""
        metadata = processed_scene['metadata']
        ships = processed_scene['ships']
        
        print(f"\n=== é¢„å¤„ç†åœºæ™¯æ‘˜è¦ ===")
        print(f"èˆ¹åªæ•°é‡: {metadata['ship_count']}")
        print(f"æ—¶é—´æ­¥æ•°: {metadata['time_steps']}")
        print(f"æ—¶é—´æ­¥é•¿: {metadata['time_step_size']}ç§’")
        print(f"æ€»æŒç»­æ—¶é—´: {metadata['total_duration']}ç§’")
        print(f"åŸç‚¹åæ ‡: ({metadata['origin_lon']:.6f}, {metadata['origin_lat']:.6f})")
        
        print(f"\nå‰3è‰˜èˆ¹åªçš„å±€éƒ¨ç‰¹å¾èŒƒå›´(ç›¸å¯¹T_h-1):")
        for i, ship in enumerate(ships[:3]):
            features = ship['features_local']
            print(f"  èˆ¹åª{i+1} (MMSI: {ship['mmsi']}):")
            print(f"    XèŒƒå›´: {features['x'].min():.1f} ~ {features['x'].max():.1f} m")
            print(f"    YèŒƒå›´: {features['y'].min():.1f} ~ {features['y'].max():.1f} m") 
            print(f"    é€Ÿåº¦èŒƒå›´: {features['v_magnitude'].min():.2f} ~ {features['v_magnitude'].max():.2f} m/s")
            print(f"    åŠ é€Ÿåº¦èŒƒå›´: {features['a_magnitude'].min():.3f} ~ {features['a_magnitude'].max():.3f} m/sÂ²")
            print(f"    èˆªå‘å˜åŒ–ç‡èŒƒå›´: {features['omega'].min():.4f} ~ {features['omega'].max():.4f} rad/s")

def main():
    """æµ‹è¯•å‡½æ•°"""
    import pickle
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    data_path = '/home/mahexing/ais_data_process/scene_generation/DI-MTP/data/per_file/POS_OK_2024-07-01_Waigaoqiao_Port_processed_batches.pkl'
    
    print("åŠ è½½æµ‹è¯•æ•°æ®...")
    with open(data_path, 'rb') as f:
        data = pickle.load(f)
    
    # åˆ›å»ºé¢„å¤„ç†å™¨ï¼ˆä½¿ç”¨30ç§’æ—¶é—´æ­¥é•¿ï¼‰
    preprocessor = MaritimeScenePreprocessor(target_time_step=30.0, num_historical_steps=5)
    
    # å¤„ç†ç¬¬ä¸€ä¸ªåœºæ™¯
    scene = data[0]
    processed = preprocessor.preprocess_scene(scene)
    
    # æ˜¾ç¤ºç»“æœæ‘˜è¦
    preprocessor.print_scene_summary(processed)
    
    # åˆ›å»ºHeteroDataç»“æ„
    print(f"\n=== åˆ›å»ºPyTorch Geometric HeteroDataç»“æ„ ===")
    hetero_data = preprocessor.create_hetero_data(processed)
    
    # æ˜¾ç¤ºHeteroDataè¯¦ç»†ç»“æ„
    preprocessor.print_hetero_data_info(hetero_data)
    
    # éªŒè¯HeteroDataç»“æ„
    print(f"\n=== HeteroDataç»“æ„éªŒè¯ ===")
    validation_results = preprocessor.validate_hetero_data(hetero_data)
    
    if validation_results['structure_valid']:
        print("âœ… HeteroDataç»“æ„éªŒè¯é€šè¿‡!")
    else:
        print("âŒ HeteroDataç»“æ„éªŒè¯å¤±è´¥!")
        for error in validation_results['errors']:
            print(f"  é”™è¯¯: {error}")
    
    # æ˜¾ç¤ºHeteroDataç»Ÿè®¡ä¿¡æ¯
    stats = validation_results['statistics']
    print(f"\nğŸ“Š HeteroDataç»Ÿè®¡ä¿¡æ¯:")
    print(f"   èˆ¹åªæ•°é‡: {stats.get('num_ships', 'N/A')}")
    print(f"   æ—¶é—´æ­¥æ•°: {stats.get('num_timesteps', 'N/A')}")
    print(f"   ç‰¹å¾ç»´åº¦: {stats.get('num_features', 'N/A')}")
    print(f"   ç‰¹å¾å¼ é‡å½¢çŠ¶: {stats.get('agent_features_shape', 'N/A')}")
    print(f"   ç‰¹å¾æ•°æ®ç±»å‹: {stats.get('agent_features_dtype', 'N/A')}")
    
    # è¾¹å…³ç³»ç»Ÿè®¡
    if 'edge_types' in stats:
        print(f"\nğŸ”— å›¾è¾¹å…³ç³»ç»Ÿè®¡:")
        for edge_info in stats['edge_types']:
            print(f"   {edge_info['type']}: {edge_info['num_edges']} æ¡è¾¹, å½¢çŠ¶: {edge_info['shape']}")
    
    # ç‰¹å¾å½’ä¸€åŒ–ç»Ÿè®¡
    if 'feature_stats' in stats:
        feature_stats = stats['feature_stats']
        print(f"\nğŸ“ˆ å½’ä¸€åŒ–åç‰¹å¾ç»Ÿè®¡:")
        feature_names = ['x', 'y', 'vx', 'vy', 'ax', 'ay', 'theta', 'omega']
        print(f"   ç‰¹å¾å‡å€¼: {[f'{feature_names[i]}={val:.3f}' for i, val in enumerate(feature_stats['mean'])]}")
        print(f"   ç‰¹å¾æ ‡å‡†å·®: {[f'{feature_names[i]}={val:.3f}' for i, val in enumerate(feature_stats['std'])]}")
        print(f"   å…¨å±€æœ€å°å€¼: {feature_stats['min']:.3f}")
        print(f"   å…¨å±€æœ€å¤§å€¼: {feature_stats['max']:.3f}")
    
    # æ˜¾ç¤ºå½’ä¸€åŒ–ç»Ÿè®¡ä¿¡æ¯
    if hasattr(hetero_data, 'normalization_stats'):
        print(f"\nğŸ”„ å½’ä¸€åŒ–ç»Ÿè®¡ä¿¡æ¯ (åŸå§‹æ•°æ®):")
        norm_stats = hetero_data.normalization_stats
        for feature, stats in norm_stats.items():
            print(f"   {feature}: å‡å€¼={stats['mean']:.3f}, æ ‡å‡†å·®={stats['std']:.3f}")
    
    # æ˜¾ç¤ºç¬¬ä¸€è‰˜èˆ¹çš„è¯¦ç»†å±€éƒ¨ç‰¹å¾
    print(f"\n=== ç¬¬ä¸€è‰˜èˆ¹è¯¦ç»†å±€éƒ¨ç‰¹å¾ (å‰3ä¸ªæ—¶é—´æ­¥, ç›¸å¯¹T_h-1) ===")
    first_ship = processed['ships'][0]['features_local']
    for i in range(min(3, len(first_ship['time_seconds']))):
        print(f"æ—¶é—´æ­¥ {i}: t={first_ship['time_seconds'][i]:.1f}s")
        print(f"  ä½ç½®: ({first_ship['x'][i]:.1f}, {first_ship['y'][i]:.1f}) m")
        print(f"  é€Ÿåº¦: ({first_ship['vx'][i]:.2f}, {first_ship['vy'][i]:.2f}) m/s, |v|={first_ship['v_magnitude'][i]:.2f} m/s")
        print(f"  åŠ é€Ÿåº¦: ({first_ship['ax'][i]:.3f}, {first_ship['ay'][i]:.3f}) m/sÂ²")
        print(f"  èˆªå‘: {first_ship['theta_deg'][i]:.1f}Â°, è§’é€Ÿåº¦: {first_ship['omega'][i]:.4f} rad/s")
        print()
    
    print(f"=== é¢„å¤„ç†å’ŒéªŒè¯å®Œæˆ ===")
    return hetero_data, validation_results

if __name__ == "__main__":
    main()
