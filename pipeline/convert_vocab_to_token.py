#!/usr/bin/env python3
"""
å°†Maritimeè¯æ±‡è¡¨è½¬æ¢ä¸ºSMARTæ¨¡å‹ä½¿ç”¨çš„tokenæ ¼å¼
"""

import torch
import pickle
import numpy as np
from pathlib import Path


def convert_maritime_vocab_to_token(vocab_path, output_path):
    """
    å°†maritime_motion_vocab.ptè½¬æ¢ä¸ºSMARTæ¨¡å‹ä½¿ç”¨çš„pklæ ¼å¼
    
    Args:
        vocab_path: è¾“å…¥çš„è¯æ±‡è¡¨è·¯å¾„ (maritime_motion_vocab.pt)
        output_path: è¾“å‡ºçš„tokenæ–‡ä»¶è·¯å¾„ (*.pkl)
    """
    print("=" * 80)
    print("ğŸ”„ è½¬æ¢Maritimeè¯æ±‡è¡¨ä¸ºTokenæ ¼å¼")
    print("=" * 80)
    
    # åŠ è½½maritimeè¯æ±‡è¡¨
    print(f"\nğŸ“‚ åŠ è½½è¯æ±‡è¡¨: {vocab_path}")
    vocab = torch.load(vocab_path, map_location='cpu', weights_only=False)
    
    # æå–shipçš„tokenå’Œtraj
    if 'token' not in vocab or 'ship' not in vocab['token']:
        raise ValueError("è¯æ±‡è¡¨æ ¼å¼ä¸æ­£ç¡®ï¼Œç¼ºå°‘ token['ship']")
    
    if 'traj' not in vocab or 'ship' not in vocab['traj']:
        raise ValueError("è¯æ±‡è¡¨æ ¼å¼ä¸æ­£ç¡®ï¼Œç¼ºå°‘ traj['ship']")
    
    if 'token_all' not in vocab or 'ship' not in vocab['token_all']:
        raise ValueError("è¯æ±‡è¡¨æ ¼å¼ä¸æ­£ç¡®ï¼Œç¼ºå°‘ token_all['ship']")
    
    ship_token = vocab['token']['ship']          # [N, 4, 2]
    ship_traj = vocab['traj']['ship']            # [N, time_steps, 3]
    ship_token_all = vocab['token_all']['ship']  # [N, time_steps, 4, 2]
    
    print(f"   Tokenå½¢çŠ¶: {ship_token.shape}")
    print(f"   Trajå½¢çŠ¶: {ship_traj.shape}")
    print(f"   Token_allå½¢çŠ¶: {ship_token_all.shape}")
    
    # è½¬æ¢ä¸ºnumpyï¼ˆå¦‚æœæ˜¯tensorï¼‰
    if isinstance(ship_token, torch.Tensor):
        ship_token = ship_token.numpy()
    if isinstance(ship_traj, torch.Tensor):
        ship_traj = ship_traj.numpy()
    if isinstance(ship_token_all, torch.Tensor):
        ship_token_all = ship_token_all.numpy()
    
    # SMARTæ¨¡å‹æœŸæœ›çš„æ ¼å¼ï¼ˆä»åŸå§‹ä»£ç æ¨æ–­ï¼‰:
    # token_data = {
    #     'token': dict with keys like 'veh', 'cyc', 'ped'
    #     'traj': dict with corresponding trajectories
    #     'token_all': dict with full time sequence polygons
    # }
    
    # å¯¹äºmaritimeåœºæ™¯ï¼Œæˆ‘ä»¬ç»Ÿä¸€ä½¿ç”¨'veh'ä½œä¸ºé”®ï¼ˆè§†èˆ¹èˆ¶ä¸ºè½¦è¾†ï¼‰
    # æˆ–è€…åˆ›å»ºå•ç‹¬çš„'ship'ç±»åˆ«
    # Maritimeåœºæ™¯åªæœ‰shipï¼Œä½†æ¨¡å‹éœ€è¦veh/ped/cycä¸‰ç§ç±»å‹
    # å°†shipæ•°æ®å¤ç”¨åˆ°æ‰€æœ‰ä¸‰ç§ç±»å‹
    token_data = {
        'token': {
            'ship': ship_token,
            'veh': ship_token,   # è½¦è¾†ï¼ˆå¤ç”¨shipï¼‰
            'ped': ship_token,   # è¡Œäººï¼ˆå¤ç”¨shipï¼‰
            'cyc': ship_token,   # è‡ªè¡Œè½¦ï¼ˆå¤ç”¨shipï¼‰
        },
        'traj': {
            'ship': ship_traj,
            'veh': ship_traj,
            'ped': ship_traj,
            'cyc': ship_traj,
        },
        'token_all': {
            'ship': ship_token_all,
            'veh': ship_token_all,
            'ped': ship_token_all,
            'cyc': ship_token_all,
        },
        'metadata': vocab.get('metadata', {})
    }
    
    # ä¿å­˜ä¸ºpklæ ¼å¼
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'wb') as f:
        pickle.dump(token_data, f)
    
    print(f"\nğŸ’¾ Tokenæ–‡ä»¶å·²ä¿å­˜: {output_path}")
    print(f"   æ–‡ä»¶å¤§å°: {output_path.stat().st_size / 1024:.2f} KB")
    
    # éªŒè¯
    print(f"\nâœ… éªŒè¯ä¿å­˜çš„æ–‡ä»¶...")
    with open(output_path, 'rb') as f:
        loaded_data = pickle.load(f)
    
    print(f"   Tokené”®: {list(loaded_data['token'].keys())}")
    print(f"   Trajé”®: {list(loaded_data['traj'].keys())}")
    print(f"   Token_allé”®: {list(loaded_data['token_all'].keys())}")
    
    for key in loaded_data['token'].keys():
        print(f"   {key} tokenå½¢çŠ¶: {loaded_data['token'][key].shape}")
        print(f"   {key} trajå½¢çŠ¶: {loaded_data['traj'][key].shape}")
        print(f"   {key} token_allå½¢çŠ¶: {loaded_data['token_all'][key].shape}")
    
    print(f"\n" + "=" * 80)
    print("âœ… è½¬æ¢å®Œæˆï¼")
    print("=" * 80)
    
    return token_data


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='è½¬æ¢Maritimeè¯æ±‡è¡¨ä¸ºTokenæ ¼å¼')
    parser.add_argument('--vocab', type=str, 
                       default='data/maritime_motion_vocab.pt',
                       help='è¾“å…¥è¯æ±‡è¡¨è·¯å¾„')
    parser.add_argument('--output', type=str,
                       default='smart/tokens/maritime_tokens.pkl',
                       help='è¾“å‡ºtokenæ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    convert_maritime_vocab_to_token(args.vocab, args.output)
    
    print("\nğŸ“ ä¸‹ä¸€æ­¥:")
    print(f"   1. Tokenæ–‡ä»¶å·²ä¿å­˜åˆ°: {args.output}")
    print(f"   2. åœ¨è®­ç»ƒé…ç½®ä¸­ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„tokenè·¯å¾„")
    print(f"   3. å¼€å§‹è®­ç»ƒ: python train.py --config configs/train/train_maritime.yaml")

